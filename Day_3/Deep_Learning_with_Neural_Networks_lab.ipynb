{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:16.884344Z",
     "start_time": "2024-01-10T07:27:16.831835Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sin\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD   # Stochastic Gradient Descent\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score as cv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Regression\n",
    "\n",
    "### Polynomial Regression\n",
    "\n",
    "Let's train a neural network on a few different shapes. First we start with a polynomial (a cubic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:18.506662Z",
     "start_time": "2024-01-10T07:27:18.450557Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create some data\n",
    "\n",
    "def f(x):\n",
    "    return x ** 3 - 5 * x + 12 + random.random()\n",
    "\n",
    "X = np.linspace(-1, 1, 1000).reshape(-1, 1)\n",
    "y = np.array(list(map(f, X)))\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:19.554587Z",
     "start_time": "2024-01-10T07:27:19.371690Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:20.156621Z",
     "start_time": "2024-01-10T07:27:20.068453Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a Feed Forward NN\n",
    "model = Sequential()\n",
    "model.add(Dense(5, activation='tanh'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "#   lr: learning rate\n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:24.512449Z",
     "start_time": "2024-01-10T07:27:20.801005Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print('Training...')\n",
    "loss = model.fit(X, y, epochs=150, validation_split=0.1, \n",
    "                 batch_size=128, verbose=False)\n",
    "print(loss.history['loss'][-1])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:26.641130Z",
     "start_time": "2024-01-10T07:27:26.348033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "plt.scatter(X, y, alpha=0.5)\n",
    "plt.plot(X, predictions, color='r', linewidth=2)\n",
    "plt.show()\n",
    "print(\"MSE\", mean_squared_error(predictions, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sine Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:28.116375Z",
     "start_time": "2024-01-10T07:27:28.069364Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sine data\n",
    "X = np.linspace(0, 2 * np.pi, 500).reshape(-1,1)\n",
    "y = np.sin(X)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:29.065377Z",
     "start_time": "2024-01-10T07:27:28.901868Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:29.762027Z",
     "start_time": "2024-01-10T07:27:29.689385Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(5, activation='tanh', input_shape=(1,)))\n",
    "model.add(Dense(1, activation='linear', input_shape=(5,)))\n",
    "\n",
    "#   lr: learning rate\n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:36.407510Z",
     "start_time": "2024-01-10T07:27:33.192731Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Training..')\n",
    "loss = model.fit(X, y, epochs=150, validation_split=0.1, \n",
    "                 batch_size=128, verbose=False)\n",
    "print(loss.history['loss'][-1])\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:37.755513Z",
     "start_time": "2024-01-10T07:27:37.513432Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, predictions, color='r')\n",
    "plt.show()\n",
    "print(\"MSE\", mean_squared_error(predictions, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:38.666637Z",
     "start_time": "2024-01-10T07:27:38.480656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the error over time\n",
    "\n",
    "plt.scatter(range(len(loss.history['loss'])), loss.history['loss'])\n",
    "\n",
    "# plt.scatter(range(len(loss.history['val_loss'])), loss.history['val_loss'], color='red')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.title('MSE by Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train longer\n",
    "\n",
    "If we train for more epochs, we can get a better regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:47.050088Z",
     "start_time": "2024-01-10T07:27:41.810241Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.linspace(0, 2 * np.pi, 1000).reshape(-1,1)\n",
    "y = np.sin(X)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5, activation='tanh', input_shape=(1,)))\n",
    "model.add(Dense(1, activation='linear', input_shape=(5,)))\n",
    "\n",
    "#   lr: learning rate\n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.05))\n",
    "\n",
    "print('Training..')\n",
    "loss = model.fit(X, y, epochs=250, validation_split=0.1, \n",
    "                 batch_size=256, verbose=False)\n",
    "print(loss.history['loss'][-1])\n",
    "print('Complete')\n",
    "\n",
    "# Plot\n",
    "predictions = model.predict(X)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, predictions, color='r')\n",
    "plt.show()\n",
    "print(\"MSE\", mean_squared_error(predictions, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a closer look at the error per training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:47.867076Z",
     "start_time": "2024-01-10T07:27:47.706207Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the error over time\n",
    "\n",
    "plt.scatter(range(len(loss.history['loss'])), loss.history['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE by Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Perform regression on the following data\n",
    "Hints:\n",
    "* Try adding a hidden layer\n",
    "* Try lowering the learning rate and using more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:51.244410Z",
     "start_time": "2024-01-10T07:27:51.193385Z"
    }
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x ** 2 * np.sin(x**2)\n",
    "\n",
    "# Sine data\n",
    "X = np.linspace(2, np.pi, 1000).reshape(-1,1)\n",
    "y = np.array(list(map(f, X)))\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:52.678590Z",
     "start_time": "2024-01-10T07:27:52.520771Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T15:52:52.445540Z",
     "start_time": "2019-12-12T15:52:52.439597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T15:52:52.459508Z",
     "start_time": "2019-12-12T15:52:52.451530Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup your model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model using MSE as your loss function and an SGD learning rate of your choice\n",
    "\n",
    "\n",
    "\n",
    "#Fit your model\n",
    "\n",
    "\n",
    "\n",
    "# Make your predictions\n",
    "\n",
    "\n",
    "# Plot predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classification\n",
    "\n",
    "We'll start with the Iris dataset (of course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:27:59.828242Z",
     "start_time": "2024-01-10T07:27:59.731851Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Break each output into indicator cols\n",
    "y_cat = pd.get_dummies(y).values\n",
    "\n",
    "print(X.shape, y_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:28:44.752279Z",
     "start_time": "2024-01-10T07:28:44.676774Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a model\n",
    "model = Sequential()\n",
    "\n",
    "# First layer - input diminsions=k features.\n",
    "model.add(Dense(4, activation='tanh', input_shape=(4,)))\n",
    "\n",
    "# Output layer - output_dim=# of output per point (in y).\n",
    "# Use 'softmax' for class probability. 'linear' for regression\n",
    "model.add(Dense(3, activation='softmax', input_shape=(4,)))\n",
    "\n",
    "# Uses categorical_crossentropy and Stochastic Gradient Descent\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:28:49.094702Z",
     "start_time": "2024-01-10T07:28:46.273280Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print('Training...')\n",
    "loss = model.fit(X, y_cat, \n",
    "                 validation_split=0.1, epochs=100, \n",
    "                 batch_size=16, verbose=False)\n",
    "\n",
    "print(loss.history['loss'][-1])   # displays categorical_crossentropy at last iteration\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:29:16.082473Z",
     "start_time": "2024-01-10T07:29:15.970551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "\n",
    "preds  = model.predict(X, verbose=False).argmax(axis=-1)\n",
    "\n",
    "print('ACCURACY: ', accuracy_score(y, preds))\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:30:08.114558Z",
     "start_time": "2024-01-10T07:30:07.935534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the error over time\n",
    "\n",
    "plt.scatter(range(len(loss.history['loss'])), loss.history['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('categorical crossentropy')\n",
    "plt.title('categorical crossentropy by Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abalone data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:30:11.452314Z",
     "start_time": "2024-01-10T07:30:11.388824Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = [\"Sex\", \"Length\", \"Diameter\", \"Height\", \"Whole Weight\",\n",
    "           \"Shucked weight\", \"Viscera weight\", \"Shell weight\", \"Rings\" ]\n",
    "df = pd.read_csv(\"./data/abalone.data\", names=columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:30:11.989566Z",
     "start_time": "2024-01-10T07:30:11.918399Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:30:32.650980Z",
     "start_time": "2024-01-10T07:30:15.214713Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(data=df, vars=columns[1:], hue=\"Sex\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:30:32.695284Z",
     "start_time": "2024-01-10T07:30:32.653059Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'M': 0, 'F': 1, 'I': 2}\n",
    "df[\"Sex\"] = df[\"Sex\"].apply(lambda x: d[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:30:32.761332Z",
     "start_time": "2024-01-10T07:30:32.697006Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:30:32.809199Z",
     "start_time": "2024-01-10T07:30:32.764073Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array(df[columns[1:]])\n",
    "y = np.array(df[\"Sex\"])\n",
    "y_cat = pd.get_dummies(y).values\n",
    "\n",
    "print(X.shape, y_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:30:43.378075Z",
     "start_time": "2024-01-10T07:30:43.292120Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a model\n",
    "model = Sequential()\n",
    "\n",
    "# input_dim = number of neurons in previous layer.\n",
    "# output_dim = number of neurons in current layer.\n",
    "\n",
    "# First layer - input_dim=k features.\n",
    "model.add(Dense(6, activation='tanh', input_shape=(8,)))\n",
    "\n",
    "#Second, hidden layer\n",
    "model.add(Dense(8, activation='tanh', input_shape=(6,)))\n",
    "\n",
    "# Output layer - output_dim=# of output per point (in y).\n",
    "# Use 'softmax' for class probability. 'linear' for regression\n",
    "model.add(Dense(3, activation='softmax', input_shape=(8,)))\n",
    "\n",
    "\n",
    "# Uses categorical_crossentropy and Stochastic Gradient Descent\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:31:04.332591Z",
     "start_time": "2024-01-10T07:30:54.205175Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print('Training...')\n",
    "loss = model.fit(X, y_cat, \n",
    "                 validation_split=0.1, epochs=50, \n",
    "                 batch_size=16, verbose=False)\n",
    "\n",
    "print(loss.history['loss'][-1])   # displays categorical_crossentropy at last iteration\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:31:50.665844Z",
     "start_time": "2024-01-10T07:31:50.311228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "\n",
    "preds  = model.predict(X, verbose=False).argmax(axis=-1)\n",
    "\n",
    "print('ACCURACY: ', accuracy_score(y, preds))\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(y, preds))\n",
    "\n",
    "# Plot the error over time\n",
    "\n",
    "plt.scatter(range(len(loss.history['loss'])), loss.history['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('categorical_crossentropy')\n",
    "plt.title('categorical_crossentropy by Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Classify the following data ([source](https://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope)). You'll need to translate the classes into integers and make dummies. Design a neural network to classify the data and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T07:32:05.100220Z",
     "start_time": "2024-01-10T07:32:05.014207Z"
    }
   },
   "outputs": [],
   "source": [
    "names = \"fLength fWidth fSize fConc fConc1 fAsym fM3Long fM3Trans fAlpha fDist class\".split()\n",
    "df = pd.read_csv(\"./data/magic04.data\", names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T15:57:52.592156Z",
     "start_time": "2019-12-12T15:52:25.322Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to change the class to an int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T15:57:52.598025Z",
     "start_time": "2019-12-12T15:52:25.334Z"
    }
   },
   "outputs": [],
   "source": [
    "# Move create your X, y and y_cat datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T15:57:52.600020Z",
     "start_time": "2019-12-12T15:52:25.345Z"
    }
   },
   "outputs": [],
   "source": [
    "# What's their shape?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T15:57:52.604762Z",
     "start_time": "2019-12-12T15:52:25.357Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a model? Why not!\n",
    "model = Sequential()\n",
    "\n",
    "# How many input dimensions does X have?\n",
    "# What are our output dimensions?\n",
    "# Build our first layer\n",
    "\n",
    "# Choose a value for the hidden layer\n",
    "\n",
    "# Create the Output layer - how many output dimensions should you have?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T15:57:52.607326Z",
     "start_time": "2019-12-12T15:52:25.367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uses categorical crossentropy and Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T15:57:52.619220Z",
     "start_time": "2019-12-12T15:52:25.375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T15:57:52.623209Z",
     "start_time": "2019-12-12T15:52:25.384Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model evaluation - maybe accuracy and confusion matrix?\n",
    "\n",
    "# Plot the error over time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Extra Practice \n",
    "\n",
    "What are better loss functions for classification problems? Can you make any of the above in this notebook better by looking at other keras losses? What about optimizing with Adam or others? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
